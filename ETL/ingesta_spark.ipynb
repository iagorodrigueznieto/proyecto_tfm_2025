{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W_jnU4SCpqzA"
      },
      "outputs": [],
      "source": [
        "# # 📦 Importar librerías necesarias\n",
        "import pyspark\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import regexp_replace, col, count, isnan, when, trim, upper, lower, expr\n",
        "from pyspark.sql.types import IntegerType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKxesDMpCU00"
      },
      "source": [
        "## GUIA DE COMANDOS SPARK PARA LA LIMPIEZA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dixbc-EYCT16"
      },
      "outputs": [],
      "source": [
        "# # 🚀 Crear sesión Spark\n",
        "# spark = SparkSession.builder.appName(\"LimpiezaDatos\").getOrCreate()\n",
        "\n",
        "# # 📥 Cargar datos desde CSV\n",
        "# df = spark.read.csv(\"archivo.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# # 👁️ Visualizar primeras filas y esquema\n",
        "# df.show(5)                 # Primeras 5 filas\n",
        "# df.printSchema()           # Tipos de columnas\n",
        "# df.columns                 # Lista de nombres de columnas\n",
        "\n",
        "# # 📊 Resumen estadístico\n",
        "# df.describe().show()       # count, mean, stddev, min, max\n",
        "# df.summary().show()        # count, mean, stddev, min, 25%, 50%, 75%, max\n",
        "\n",
        "# # 🧼 Limpieza de datos\n",
        "\n",
        "# ## 1. Verificar nulos\n",
        "# df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns]).show()\n",
        "\n",
        "# ## 2. Eliminar filas con nulos\n",
        "# df = df.dropna()\n",
        "\n",
        "# ## 3. Rellenar nulos con valores por defecto\n",
        "# df = df.fillna({\n",
        "#     \"columna_numerica\": 0,\n",
        "#     \"columna_categorica\": \"desconocido\"\n",
        "# })\n",
        "\n",
        "# ## 4. Reemplazar valores nulos en una columna\n",
        "# df = df.withColumn(\"columna\", when(col(\"columna\").isNull(), \"valor_defecto\").otherwise(col(\"columna\")))\n",
        "\n",
        "# ## 5. Eliminar duplicados\n",
        "# df = df.dropDuplicates()  # O: df.dropDuplicates([\"columna_clave\"])\n",
        "\n",
        "# ## 6. Renombrar columnas\n",
        "# df = df.withColumnRenamed(\"Col Antiguo\", \"col_nuevo\")\n",
        "\n",
        "# ## 7. Conversión de tipos\n",
        "# df = df.withColumn(\"edad\", col(\"edad\").cast(\"int\"))\n",
        "# df = df.withColumn(\"fecha\", col(\"fecha\").cast(\"date\"))\n",
        "\n",
        "# ## 8. Limpiar y modificar texto\n",
        "# df = df.withColumn(\"col_trim\", trim(col(\"col_texto\")))\n",
        "# df = df.withColumn(\"col_upper\", upper(col(\"col_texto\")))\n",
        "# df = df.withColumn(\"col_lower\", lower(col(\"col_texto\")))\n",
        "\n",
        "# ## 9. Crear o modificar columnas\n",
        "# df = df.withColumn(\"suma\", col(\"col1\") + col(\"col2\"))\n",
        "# df = df.withColumn(\"categoria_edad\", when(col(\"edad\") >= 18, \"adulto\").otherwise(\"menor\"))\n",
        "\n",
        "# ## 10. Filtrar datos\n",
        "# df = df.filter(col(\"ingresos\") > 1000)\n",
        "# df = df.filter(col(\"pais\") == \"España\")\n",
        "\n",
        "# ## 11. Eliminar columnas innecesarias\n",
        "# df = df.drop(\"columna_innecesaria\")  # Una\n",
        "# df = df.drop(*[\"col1\", \"col2\"])      # Varias\n",
        "\n",
        "# ## 12. Reemplazar valores\n",
        "# df = df.replace(\"desconocido\", \"otros\", subset=[\"columna\"])\n",
        "\n",
        "# ## 13. Ver valores únicos y categorías\n",
        "# df.select(\"columna\").distinct().show()\n",
        "# df.groupBy(\"categoria\").count().show()\n",
        "\n",
        "# # 📈 Visualización básica (limitada en Spark)\n",
        "# df.show(10)                       # Muestra 10 filas\n",
        "# df.groupBy(\"columna\").count().show()  # Conteo por categoría\n",
        "\n",
        "# # Si quieres graficar: convertir a Pandas (⚠️ cuidado con datasets grandes)\n",
        "# df_pd = df.limit(1000).toPandas()\n",
        "\n",
        "# # Ejemplo: usar matplotlib o seaborn\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.histplot(df_pd[\"edad\"], bins=20)\n",
        "# plt.title(\"Distribución de edad\")\n",
        "# plt.show()\n",
        "\n",
        "# sns.countplot(data=df_pd, x=\"categoria\")\n",
        "# plt.title(\"Conteo por categoría\")\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "32AZqecHSln9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "25/06/08 12:33:48 WARN Utils: Your hostname, DESKTOP-JCU85UN, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
            "25/06/08 12:33:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/06/08 12:33:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('tfm_2025').getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Primer archivo \"EloRatings.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MFHw0HMS0q1",
        "outputId": "1cd1b801-de68-4387-c833-54f769c7da6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---------+-------+-------+\n",
            "|      date|     club|country|    elo|\n",
            "+----------+---------+-------+-------+\n",
            "|2000-07-01|   Aachen|    GER| 1453.6|\n",
            "|2000-07-01|  Aalborg|    DEN|1482.61|\n",
            "|2000-07-01|    Aalst|    BEL|1337.53|\n",
            "|2000-07-01|   Aarhus|    DEN|1381.46|\n",
            "|2000-07-01| Aberdeen|    SCO|1360.43|\n",
            "|2000-07-01|Adanaspor|    TUR|1380.76|\n",
            "|2000-07-01|      AEK|    GRE|1599.31|\n",
            "|2000-07-01|      AIK|    SWE|1563.87|\n",
            "|2000-07-01|  Ajaccio|    FRA|1470.87|\n",
            "|2000-07-01|     Ajax|    NED|1604.75|\n",
            "+----------+---------+-------+-------+\n",
            "only showing top 10 rows\n",
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- club: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- elo: double (nullable = true)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['date', 'club', 'country', 'elo']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargar el primer csv\n",
        "df = spark.read.csv(\"../Data/EloRatings.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Ver las primeras filas\n",
        "df.show(10)\n",
        "df.printSchema()\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i62dFf02UGBm",
        "outputId": "578ebe77-a576-404c-ea6b-586ce080a009"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 9:===================>                                       (1 + 2) / 3]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------+-------+------------------+\n",
            "|summary|        club|country|               elo|\n",
            "+-------+------------+-------+------------------+\n",
            "|  count|      242591| 242591|            242591|\n",
            "|   mean|        NULL|   NULL|1505.1128453652552|\n",
            "| stddev|        NULL|   NULL| 155.5037772431839|\n",
            "|    min|A. Sebatspor|    AUT|           1069.68|\n",
            "|    25%|        NULL|   NULL|           1394.83|\n",
            "|    50%|        NULL|   NULL|           1486.94|\n",
            "|    75%|        NULL|   NULL|           1606.08|\n",
            "|    max|      Zwolle|    TUR|           2107.48|\n",
            "+-------+------------+-------+------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "def mostrar_sumario(df):\n",
        "    \"\"\"\n",
        "    Muestra un sumario del dataset.\n",
        "    Explicacion:\n",
        "        - Usa la funcion 'describe()' para mostrar las siguientes metricas:\n",
        "            - El conteo de filas por columna.\n",
        "            - La media de los valores de las columnas numericas (muestra NULL si no es numerica).\n",
        "            - La desviacion  estandar de los valores de las columnas numericas (muestra NULL si no es numerica).\n",
        "            - El valor minimo de cada columna.\n",
        "            - El valor maximo de cada columna.\n",
        "        - Devuelve el DataFrame con las metricas.\n",
        "    Args:\n",
        "        df: DataFrame a analizar\n",
        "\n",
        "    Returns:\n",
        "        Un DataFrame con las métricas del dataset.\n",
        "    \"\"\"\n",
        "    return df.summary()\n",
        "\n",
        "mostrar_sumario(df).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d56M5cUpDukq"
      },
      "source": [
        "## CONTAMOS LOS NULOS QUE HAY EN CADA COLUMNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----+-------+---+\n",
            "|date|club|country|elo|\n",
            "+----+----+-------+---+\n",
            "|   0|   0|      0|  0|\n",
            "+----+----+-------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def contar_nulos_por_columna(df):\n",
        "    \"\"\"\n",
        "    Calcula el numero de valores nulos en cada columna del DataFrame.\n",
        "    Explicacion:\n",
        "        - Itera sobre cada columna del DataFrame utilizando 'df.columns'.\n",
        "        - Usa la funcion 'expr()' que utiliza una expresion SQL para contar los valores nulos en cada columna.\n",
        "        - Asigna '1' si el valor es nulo y '0' si no es nulo.\n",
        "        - Renombra la columna con '.alias(c)' para mantener el nombre original.\n",
        "        - Selecciona y aplica la transformacion en todas las columnas dinamicamente con 'df.select([...])'.\n",
        "        - Devuelve el DataFrame con los conteos de nulos.\n",
        "    Args:\n",
        "        df: DataFrame a analizar\n",
        "\n",
        "    Returns:\n",
        "        Un DataFrame con las mismas columnas del DataFrame original\n",
        "        y una fila que indica el numero de valores nulos por columna.\n",
        "    \"\"\"\n",
        "    # return df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
        "    return df.select([expr(f\"sum(case when {c} is null then 1 else 0 end)\").alias(c) for c in df.columns])\n",
        "\n",
        "contar_nulos_por_columna(df).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 18:===================>                                      (1 + 2) / 3]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----+-------+---+\n",
            "|date|club|country|elo|\n",
            "+----+----+-------+---+\n",
            "+----+----+-------+---+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# COMPROBAR SI HAY VALORES DUPLICADOS\n",
        "df.exceptAll(df.dropDuplicates()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H30N_BGKFkx-"
      },
      "outputs": [],
      "source": [
        "# Mostrar nombres unicos de clubs\n",
        "pd.Series(df.values.flatten()).unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao-igMB9WkGp"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"gross\", regexp_replace(col(\"gross\"), \"[$,M]\", \"\")) # Eliminamo $ y M.\n",
        "df = df.withColumn(\"gross\", (col(\"gross\").cast(\"double\") * 1000000).cast(\"int\")) # Convertimos a float, multiplicamos por 1 millon, y lo convertimos a integer.\n",
        "df = df.withColumnRenamed(\"gross\", \"gross(M)\") # Cambiamos el nombre de la columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI6eb_BZYX0t"
      },
      "outputs": [],
      "source": [
        "# Ruta donde quieres guardar el archivo CSV en Google Drive\n",
        "output_path = \"../Data/EloRatings_cleaned\"\n",
        "\n",
        "# Guardar el DataFrame en formato CSV\n",
        "# Spark por defecto guarda en particiones\n",
        "# Para guardarlo en un solo archivo, usar repartition(1) antes de 'write'\n",
        "df.repartition(1).write.csv(output_path, header=True, mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Segundo archivo \"Matches.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a8TjweTTYv2W"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
